{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937008d",
   "metadata": {},
   "source": [
    "## Question 1. Install Spark and PySpark\n",
    "Answer:3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e77fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61558c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv -o fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43935823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266018f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,StringType,true),StructField(SR_Flag,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head(5)\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdc2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('fhvhv_tripdata_2021-02.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd8fcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(SR_Flag,DoubleType,true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.createDataFrame(df_pandas).show()\n",
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dc2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num', types.StringType() ,True),\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2517d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9457c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0baaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()\n",
    "# df.schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b154dd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hvfhs_license_num: string, dispatching_base_num: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int, SR_Flag: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f6baddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('06_homework_week_5', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033bb4cd",
   "metadata": {},
   "source": [
    "## Question 2. HVFHW February 2021\n",
    "What's the size of the folder with results (in MB)?\n",
    "Answer: 150M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cca04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive L is H:\\Data-Python\n",
      " Volume Serial Number is 0464-DD1C\n",
      "\n",
      " Directory of L:\\python-virtual-environments\\de\\06_homework_week_5\n",
      "\n",
      "27/02/2022  11:10    <DIR>          .\n",
      "27/02/2022  11:10    <DIR>          ..\n",
      "27/02/2022  11:10           158,208 .part-00000-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           143,752 .part-00001-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           147,408 .part-00002-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           143,320 .part-00003-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           147,768 .part-00004-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           143,496 .part-00005-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           147,776 .part-00006-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10           132,136 .part-00007-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet.crc\n",
      "27/02/2022  11:10                 8 ._SUCCESS.crc\n",
      "27/02/2022  11:10        20,249,592 part-00000-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,398,832 part-00001-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,866,948 part-00002-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,343,825 part-00003-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,913,019 part-00004-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,366,146 part-00005-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        18,914,130 part-00006-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10        16,911,911 part-00007-8621df0e-097d-41d1-b49a-6b15f5e5f0ea-c000.snappy.parquet\n",
      "27/02/2022  11:10                 0 _SUCCESS\n",
      "              18 File(s)    150,128,275 bytes\n",
      "               2 Dir(s)  49,383,936,000 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir 06_homework_week_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "861475bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175b5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|11613942|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) from trips\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324efdaa",
   "metadata": {},
   "source": [
    "## Question 3. Count records\n",
    "-- How many taxi trips were there on February 15?\n",
    "-- Consider only trips that started on February 15.\n",
    "Ans: 367170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT date(pickup_datetime) as pickup_date, count(*) from trips \n",
    "          group by pickup_date order by pickup_date \"\"\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfbbf4",
   "metadata": {},
   "source": [
    "## Question 4. Longest trip for each day\n",
    "\n",
    "Now calculate the duration for each trip.\n",
    "Trip starting on which day was the longest? \n",
    "Ans: 11/02/2021 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top length in seconds \n",
    "spark.sql(\"\"\"SELECT bigint(dropoff_datetime)-bigint(pickup_datetime) as trip_len_seconds, pickup_datetime from trips  \n",
    "          order by 1 desc LIMIT 5 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb511b",
   "metadata": {},
   "source": [
    "## Question 5. Most frequent `dispatching_base_num`\n",
    "\n",
    "Now find the most frequently occurring `dispatching_base_num` \n",
    "in this dataset.\n",
    "\n",
    "How many stages this spark job has?\n",
    "\n",
    "> Note: the answer may depend on how you write the query,\n",
    "> so there are multiple correct answers. \n",
    "> Select the one you have.\n",
    "Ans: 1741\n",
    "Ans: 3 Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca44313",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT dispatching_base_num, count(*) from trips  \n",
    "          group by dispatching_base_num order by dispatching_base_num desc LIMIT 1 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24365e",
   "metadata": {},
   "source": [
    "## Question 6. Most common locations pair\n",
    "\n",
    "Find the most common pickup-dropoff pair. \n",
    "For example:\n",
    "\"Jamaica Bay / Clinton East\"\n",
    "Enter two zone names separated by a slash\n",
    "If any of the zone names are unknown (missing), use \"Unknown\". For example, \"Unknown / Clinton East\". \n",
    "Ans: East New York/East New York (45041 records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67001afd",
   "metadata": {},
   "source": [
    "## Bonus question. Join type\n",
    "\n",
    "(not graded) \n",
    "For finding the answer to Q6, you'll need to perform a join.\n",
    "What type of join is it?\n",
    "And how many stages your spark job has?\n",
    "Ans: Outer\n",
    "Ans: 2 Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zones.dtypes\n",
    "df_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c33b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('LocationID', types.IntegerType() ,True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8748a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bf216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611deda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT * from zones order by LocationID\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc938a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"select concat_ws('/',coalesce(pickup_zone.Zone,'Unknown'), coalesce(dropoff_zone.Zone,'Unknown')) as pickupdropoff,\n",
    "    count(*)\n",
    "    from trips\n",
    "    left join zones as pickup_zone on pickup_zone.LocationID = trips.PULocationID \n",
    "    left join zones as dropoff_zone on dropoff_zone.LocationId = trips.DOLocationID\n",
    "    group by 1\n",
    "    order by 2 desc\n",
    "    \"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfce6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()\n",
    "df.dtypes\n",
    "# df_zones.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
